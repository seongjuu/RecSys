{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context-aware hybrid \n",
    "\n",
    "# 필요한 모듈 모두 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Add, Multiply, Concatenate, Embedding\n",
    "from tensorflow.keras.layers import Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adamax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>years</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0955928C2RRWOWZN7UC</td>\n",
       "      <td>B00191WVF6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Friday</td>\n",
       "      <td>February</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0955928C2RRWOWZN7UC</td>\n",
       "      <td>B005WY3TMA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0955928C2RRWOWZN7UC</td>\n",
       "      <td>B0090XWU8S</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>April</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0955928C2RRWOWZN7UC</td>\n",
       "      <td>B00FXYTLIK</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.7264</td>\n",
       "      <td>Friday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0955928C2RRWOWZN7UC</td>\n",
       "      <td>B00HMZG3YS</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>Friday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99737</th>\n",
       "      <td>AZZYW4YOE1B6E</td>\n",
       "      <td>B009AYLDSU</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99738</th>\n",
       "      <td>AZZYW4YOE1B6E</td>\n",
       "      <td>B00E055H5O</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>Monday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99739</th>\n",
       "      <td>AZZYW4YOE1B6E</td>\n",
       "      <td>B00E8HGWIK</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99740</th>\n",
       "      <td>AZZYW4YOE1B6E</td>\n",
       "      <td>B00M58CMTM</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>October</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99741</th>\n",
       "      <td>AZZYW4YOE1B6E</td>\n",
       "      <td>B00VWVZ0V0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99742 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    item_id     user_id  rating  votes  years  compound_score  \\\n",
       "0      A0955928C2RRWOWZN7UC  B00191WVF6       4      0   2017          0.0000   \n",
       "1      A0955928C2RRWOWZN7UC  B005WY3TMA       4      0   2015          0.4404   \n",
       "2      A0955928C2RRWOWZN7UC  B0090XWU8S       4      0   2017          0.0000   \n",
       "3      A0955928C2RRWOWZN7UC  B00FXYTLIK       4      0   2015          0.7264   \n",
       "4      A0955928C2RRWOWZN7UC  B00HMZG3YS       4      0   2015          0.6369   \n",
       "...                     ...         ...     ...    ...    ...             ...   \n",
       "99737         AZZYW4YOE1B6E  B009AYLDSU       5      2   2013          0.9798   \n",
       "99738         AZZYW4YOE1B6E  B00E055H5O       4      0   2015          0.8402   \n",
       "99739         AZZYW4YOE1B6E  B00E8HGWIK       5      0   2013          0.9940   \n",
       "99740         AZZYW4YOE1B6E  B00M58CMTM       5      4   2014          0.9856   \n",
       "99741         AZZYW4YOE1B6E  B00VWVZ0V0       4      0   2016          0.8417   \n",
       "\n",
       "             day     month  \n",
       "0         Friday  February  \n",
       "1         Sunday      June  \n",
       "2       Saturday     April  \n",
       "3         Friday      July  \n",
       "4         Friday      July  \n",
       "...          ...       ...  \n",
       "99737    Tuesday  December  \n",
       "99738     Monday       May  \n",
       "99739     Sunday  December  \n",
       "99740  Wednesday   October  \n",
       "99741    Tuesday  December  \n",
       "\n",
       "[99742 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv 파일 불러오기\n",
    "ratings = pd.read_csv('/home/sjkim/recommendSystem/finalproject/change_df.csv', encoding='latin-1', index_col=0)\n",
    "ratings['rating'] = ratings['rating'].astype(int)\n",
    "ratings['votes'] = ratings['votes'].astype(int)\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'])\n",
    "\n",
    "# 요일 추가하기\n",
    "ratings['day'] = ratings['timestamp'].dt.day_name()\n",
    "# 월 추가하기\n",
    "ratings['month'] = ratings['timestamp'].dt.month_name()\n",
    "\n",
    "# 필요없는 컬럼 삭제\n",
    "ratings = ratings.drop(columns = ['timestamp','text', 'neg_score', 'neu_score', 'pos_score'])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorechange(n):\n",
    "  if n<=0 :\n",
    "    r = 'neg'\n",
    "  else : \n",
    "    r = 'pos'\n",
    "  return r\n",
    "\n",
    "def votechange(n):\n",
    "  if n==0:\n",
    "    r = 'not voted'\n",
    "  else :\n",
    "    r = 'voted'\n",
    "  return r\n",
    "\n",
    "ratings['votes'] = ratings['votes'].apply(votechange)\n",
    "ratings.rename(columns = {'compound_score' : 'sentiment'}, inplace = True)\n",
    "ratings['sentiment'] = ratings['sentiment'].apply(scorechange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일변수 더비변수로 만들기\n",
    "daydummies = ratings.copy()\n",
    "daydummies = daydummies.drop(['user_id', 'item_id', 'rating', 'votes', 'years', 'sentiment', 'month'], axis=1)\n",
    "daydummies = pd.get_dummies(daydummies, columns=['day'])\n",
    "\n",
    "# 월변수 더비변수로 만들기\n",
    "monthdummies = ratings.copy()\n",
    "monthdummies = monthdummies.drop(['user_id', 'item_id', 'rating', 'votes', 'years', 'sentiment', 'day'], axis=1)\n",
    "monthdummies = pd.get_dummies(monthdummies, columns=['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_id + 요일변수들만 넣은 데이터 프레임\n",
    "days = ratings.join(daydummies, how='left')\n",
    "days = days[['item_id', 'day_Monday', 'day_Tuesday', 'day_Wednesday', 'day_Thursday', 'day_Friday', 'day_Saturday', 'day_Sunday']]\n",
    "\n",
    "# item_id + 월변수들만 넣은 데이터 프레임\n",
    "months = ratings.join(monthdummies, how='left')\n",
    "months = months[['item_id', 'month_January', 'month_February', 'month_March', 'month_April', 'month_May', 'month_June', 'month_July', 'month_August', 'month_September', 'month_October', 'month_November', 'month_December']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제품 가장 많이 팔린 요일 구하기\n",
    "a = days.groupby('item_id').sum(1).values.argmax(axis=1)\n",
    "b = days.groupby('item_id').sum(1)\n",
    "b['day'] = a\n",
    "days_new = b['day'].to_frame()\n",
    "\n",
    "# 제품 가장 많이 팔린 달 구하기\n",
    "c = months.groupby('item_id').sum(1).values.argmax(axis=1)\n",
    "d = months.groupby('item_id').sum(1)\n",
    "d['month'] = c\n",
    "months_new = d['month'].to_frame()\n",
    "\n",
    "def get_day_name(n):\n",
    "    if n == 0:\n",
    "        d = 'Monday'\n",
    "    elif n == 1:\n",
    "        d = 'Tuesday'\n",
    "    elif n == 2:\n",
    "        d = 'Wednesday'\n",
    "    elif n == 3:\n",
    "        d = 'Thursday'\n",
    "    elif n == 4:\n",
    "        d = 'Friday'\n",
    "    elif n == 5:\n",
    "        d = 'Saturday'\n",
    "    else:\n",
    "        d = 'Sunday'\n",
    "    return d\n",
    "\n",
    "def get_month_name(n):\n",
    "    if n == 0:\n",
    "        m = 'January'\n",
    "    elif n == 1:\n",
    "        m = 'February'\n",
    "    elif n == 2:\n",
    "        m = 'March'\n",
    "    elif n == 3:\n",
    "        m = 'April'\n",
    "    elif n == 4:\n",
    "        m = 'May'\n",
    "    elif n == 5:\n",
    "        m = 'June'\n",
    "    elif n == 6:\n",
    "        m = 'July'\n",
    "    elif n == 7:\n",
    "        m = 'August'\n",
    "    elif n == 8:\n",
    "        m = 'September'\n",
    "    elif n == 9:\n",
    "        m = 'October'\n",
    "    elif n == 10:\n",
    "        m = 'November'\n",
    "    else:\n",
    "        m = 'December'\n",
    "    return m\n",
    "\n",
    "days_new['day'] = days_new['day'].apply(get_day_name)\n",
    "months_new['month'] = months_new['month'].apply(get_month_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 one-hot encoding해주기\n",
    "daydummies2 = days_new.copy()\n",
    "daydummies2 = pd.get_dummies(daydummies2, columns=['day'])\n",
    "\n",
    "# 다시 one-hot encoding해주기\n",
    "monthdummies2 = months_new.copy()\n",
    "monthdummies2 = pd.get_dummies(monthdummies2, columns=['month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FM 변수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User encoding\n",
    "user_dict = {}\n",
    "for i in set(ratings['user_id']):\n",
    "    user_dict[i] = len(user_dict)\n",
    "n_user = len(user_dict)\n",
    "\n",
    "# Item encoding\n",
    "item_dict = {}\n",
    "start_point = n_user\n",
    "for i in set(ratings['item_id']):\n",
    "    item_dict[i] = start_point + len(item_dict)\n",
    "n_item = len(item_dict)\n",
    "start_point += n_item\n",
    "\n",
    "# vote encoding\n",
    "vote_dict = {}\n",
    "for i in set(ratings['votes']):\n",
    "    vote_dict[i] = start_point + len(vote_dict)\n",
    "n_vote = len(vote_dict)\n",
    "start_point += n_vote\n",
    "\n",
    "#year encoding\n",
    "year_dict = {}\n",
    "for i in set(ratings['years']):\n",
    "    year_dict[i] = start_point + len(year_dict)\n",
    "n_year = len(year_dict)\n",
    "start_point += n_year\n",
    "\n",
    "# sentiment encoding\n",
    "sentiment_dict = {}\n",
    "for i in set(ratings['sentiment']):\n",
    "    sentiment_dict[i] = start_point + len(sentiment_dict)\n",
    "n_sentiment = len(sentiment_dict)\n",
    "start_point += n_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10097"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = shuffle(ratings)\n",
    "\n",
    "num_x = start_point             # Total number of x\n",
    "num_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.mean(x['rating'])\n",
    "def generate_x(x) :\n",
    "    # Generate X data\n",
    "    data = []\n",
    "    y = []\n",
    "    w0 = np.mean(x['rating'])\n",
    "    for i in range(len(x)):\n",
    "        case = x.iloc[i]\n",
    "        x_index = []\n",
    "        x_value = []\n",
    "        x_index.append(user_dict[case['user_id']])     # User id encoding\n",
    "        x_value.append(1.)\n",
    "        x_index.append(item_dict[case['item_id']])    # item id encoding\n",
    "        x_value.append(1.)\n",
    "        x_index.append(vote_dict[case['votes']])   # vote encoding\n",
    "        x_value.append(1.)\n",
    "        x_index.append(year_dict[case['years']])       # year encoding\n",
    "        x_value.append(1.)\n",
    "        x_index.append(sentiment_dict[case['sentiment']]) #sentiment encoding\n",
    "        x_value.append(1.)\n",
    "        #x_index.append(day_dict[case['day']]) #day encoding\n",
    "        #x_value.append(1.)\n",
    "\n",
    "        data.append([x_index, x_value])\n",
    "        y.append(case['rating'] - w0)\n",
    "        if (i % 10000) == 0:\n",
    "            print('Encoding ', i, ' cases...')\n",
    "\n",
    "    \n",
    "    return data, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(set(ratings.user_id)) + 1      # Number of users\n",
    "M = len(set(ratings.item_id)) + 1      # Number of items\n",
    "\n",
    "# train test 분리\n",
    "TRAIN_SIZE = 0.7\n",
    "ratings = shuffle(ratings)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]\n",
    "context_train = pd.merge(ratings_train, daydummies2, on='item_id')      # Adding context variables\n",
    "context_train = pd.merge(context_train, monthdummies2, on='item_id')\n",
    "context_train = context_train.drop(['item_id', 'user_id', 'rating', 'votes', 'years', 'sentiment', 'day', 'month'], axis=1)\n",
    "context_test = pd.merge(ratings_test, daydummies2, on='item_id')\n",
    "context_test = pd.merge(context_test, monthdummies2, on='item_id')\n",
    "context_test = context_test.drop(['user_id', 'item_id', 'rating', 'votes', 'years', 'sentiment', 'day', 'month'], axis=1)\n",
    "\n",
    "ratings = ratings.pivot(index = 'user_id', columns ='item_id', values = 'rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding  0  cases...\n",
      "Encoding  10000  cases...\n",
      "Encoding  20000  cases...\n",
      "Encoding  30000  cases...\n",
      "Encoding  40000  cases...\n",
      "Encoding  50000  cases...\n",
      "Encoding  60000  cases...\n"
     ]
    }
   ],
   "source": [
    "train_data, train_y = generate_x(ratings_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding  0  cases...\n",
      "Encoding  10000  cases...\n",
      "Encoding  20000  cases...\n"
     ]
    }
   ],
   "source": [
    "test_data, test_y = generate_x(ratings_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.962119 ; Test RMSE = 0.963537\n",
      "Iteration: 20 ; Train RMSE = 0.946699 ; Test RMSE = 0.952122\n",
      "Iteration: 30 ; Train RMSE = 0.937488 ; Test RMSE = 0.946686\n",
      "Iteration: 40 ; Train RMSE = 0.926146 ; Test RMSE = 0.940024\n",
      "Iteration: 50 ; Train RMSE = 0.910598 ; Test RMSE = 0.931214\n",
      "Iteration: 60 ; Train RMSE = 0.890165 ; Test RMSE = 0.920540\n",
      "Iteration: 70 ; Train RMSE = 0.866397 ; Test RMSE = 0.909659\n",
      "Iteration: 80 ; Train RMSE = 0.842373 ; Test RMSE = 0.900701\n",
      "Iteration: 90 ; Train RMSE = 0.820964 ; Test RMSE = 0.895040\n",
      "Iteration: 100 ; Train RMSE = 0.803398 ; Test RMSE = 0.892708\n",
      "Iteration: 110 ; Train RMSE = 0.789166 ; Test RMSE = 0.892799\n",
      "103 0.8925152955860238\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 모델 코드 넣기\n",
    "class FM():\n",
    "    def __init__(self, N, K, train_data, test_data, train_y, test_y, alpha, beta, iterations=100, tolerance=0.005, l2_reg=True, verbose=True):\n",
    "        self.K = K          # Number of latent factors\n",
    "        self.N = N          # Number of x (variables)\n",
    "        # self.n_cases = len(data)            # N of observations\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.l2_reg = l2_reg\n",
    "        self.tolerance = tolerance\n",
    "        self.verbose = verbose\n",
    "        # w 초기화\n",
    "        self.w = np.random.normal(scale=1./self.N, size=(self.N))\n",
    "        # v 초기화\n",
    "        self.v = np.random.normal(scale=1./self.K, size=(self.N, self.K))\n",
    "        # Train/Test 분리\n",
    "        self.train_x = train_data\n",
    "        self.test_x = test_data\n",
    "        self.train_y = train_y\n",
    "        self.test_y = test_y\n",
    "   \n",
    "    def test(self):                                     # Training 하면서 RMSE 계산 \n",
    "        # SGD를 iterations 숫자만큼 수행\n",
    "        best_RMSE = 10000\n",
    "        best_iteration = 0\n",
    "        training_process = []\n",
    "        best_pred = []\n",
    "        for i in range(self.iterations):\n",
    "            rmse1 = self.sgd(self.train_x, self.train_y)                # SGD & Train RMSE 계산\n",
    "            y_pred, rmse2 = self.test_rmse(self.test_x, self.test_y)    # Test RMSE 계산    \n",
    "            training_process.append((i, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.6f ; Test RMSE = %.6f\" % (i+1, rmse1, rmse2))\n",
    "            if best_RMSE > rmse2:                       # New best record\n",
    "                best_RMSE = rmse2\n",
    "                best_iteration = i\n",
    "                best_pred = y_pred\n",
    "            elif (rmse2 - best_RMSE) > self.tolerance:  # RMSE is increasing over tolerance\n",
    "                break\n",
    "        print(best_iteration, best_RMSE)\n",
    "        return training_process, best_pred, best_RMSE\n",
    "        \n",
    "    # w, v 업데이트를 위한 Stochastic gradient descent \n",
    "    def sgd(self, x_data, y_data):\n",
    "        y_pred = []\n",
    "        for data, y in zip(x_data, y_data):\n",
    "            x_idx = data[0]\n",
    "            x_0 = np.array(data[1])     # xi axis=0 [1, 2, 3]\n",
    "            x_1 = x_0.reshape(-1, 1)    # xi axis=1 [[1], [2], [3]]\n",
    "    \n",
    "            # biases\n",
    "            bias_score = np.sum(self.w[x_idx] * x_0)\n",
    "            \n",
    "            # score 계산\n",
    "            vx = self.v[x_idx] * (x_1)          # v matrix * x\n",
    "            sum_vx = np.sum(vx, axis=0)         # sigma(vx)\n",
    "            sum_vx_2 = np.sum(vx * vx, axis=0)  # ( v matrix * x )의 제곱\n",
    "            latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
    "\n",
    "            # 예측값 계산\n",
    "            y_hat = bias_score + latent_score\n",
    "            y_pred.append(y_hat)\n",
    "            error = y - y_hat\n",
    "            # w, v 업데이트\n",
    "            if self.l2_reg:     # regularization이 있는 경우\n",
    "                self.w[x_idx] += error * self.alpha * (x_0 - self.beta * self.w[x_idx])\n",
    "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1) - self.beta * self.v[x_idx])\n",
    "            else:               # regularization이 없는 경우\n",
    "                self.w[x_idx] += error * self.alpha * x_0\n",
    "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1))\n",
    "        return RMSE(y_data, y_pred)\n",
    "            \n",
    "    def test_rmse(self, x_data, y_data):\n",
    "        y_pred = []\n",
    "        for data , y in zip(x_data, y_data):\n",
    "            y_hat = self.predict(data[0], data[1])\n",
    "            y_pred.append(y_hat)\n",
    "        return np.array(y_pred), RMSE(y_data, y_pred)\n",
    "\n",
    "    def predict(self, idx, x):\n",
    "        # idx = self.user_id_index[idx]\n",
    "        # x = self.item_id_index[x]\n",
    "        x_0 = np.array(x)\n",
    "        x_1 = x_0.reshape(-1, 1)\n",
    "\n",
    "        # biases\n",
    "        bias_score = np.sum(self.w[idx] * x_0)\n",
    "\n",
    "        # score 계산\n",
    "        vx = self.v[idx] * (x_1)\n",
    "        sum_vx = np.sum(vx, axis=0)\n",
    "        sum_vx_2 = np.sum(vx * vx, axis=0)\n",
    "        latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
    "\n",
    "        # 예측값 계산\n",
    "        y_hat = bias_score + latent_score\n",
    "        return y_hat\n",
    "\n",
    "    def predict_one(self, user_id, item_id):\n",
    "        x_idx = np.array([user_dict[user_id], item_dict[item_id]])\n",
    "        x_data = np.array([1, 1])\n",
    "        return self.predict(x_idx, x_data) + w0\n",
    "# FM\n",
    "K = 260\n",
    "fm1 = FM(num_x, K, train_data, test_data, train_y, test_y, alpha=0.0001, beta=0.007, iterations=900, tolerance=0.0005)\n",
    "training_process, result0, rmse = fm1.test()  \n",
    "# print('FM RMSE:' , rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째 모델 Best-seller 코드 \n",
    "def bestseller(user_id, item_id):\n",
    "    train_mean = ratings_train.groupby(['item_id'])['rating'].mean()\n",
    "    try:\n",
    "        rating = train_mean[item_id]\n",
    "    except:\n",
    "        rating = 4.4\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상황변수 고려한 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context-aware recommendation ###########################################################################\n",
    "def recommender0(recomm_list, mf):\n",
    "    recommendations = []\n",
    "    for i in range(len(recomm_list)):\n",
    "        recommendations.append(fm1.predict_one(recomm_list[i,1], recomm_list[i,0]))\n",
    "    return np.array(recommendations)\n",
    "\n",
    "def recommender1(recomm_list): # bs\n",
    "    id_pairs = zip(recomm_list[:, 1], recomm_list[:, 0])\n",
    "    recommendations = np.array([bestseller(user, item) for (user, item) in id_pairs])\n",
    "    return recommendations\n",
    "\n",
    "# RMSE 계산을 위한 함수\n",
    "def RMSE2(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "\n",
    "recomm_list = np.array(ratings_train.iloc[:, [0, 1]])       # Data for training context-DL model\n",
    "train0 = recommender0(recomm_list, fm1)\n",
    "train1 = recommender1(recomm_list)\n",
    "\n",
    "recomm_list = np.array(ratings_test.iloc[:, [0, 1]])        # Data for testing context-DL model\n",
    "test0 = recommender0(recomm_list, fm1)\n",
    "test1 = recommender1(recomm_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 19:26:00.384870: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-04 19:26:00.384897: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-04 19:26:00.385312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/sjkim/.conda/envs/seongju/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adamax.py:99: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2182/2182 [==============================] - 15s 6ms/step - loss: 2.4373 - mean_squared_error: 7.1463 - RMSE: 2.4373 - val_loss: 0.9830 - val_mean_squared_error: 0.9896 - val_RMSE: 0.9828\n",
      "Epoch 2/100\n",
      "2182/2182 [==============================] - 15s 7ms/step - loss: 0.9143 - mean_squared_error: 0.8757 - RMSE: 0.9143 - val_loss: 0.9301 - val_mean_squared_error: 0.9082 - val_RMSE: 0.9296\n",
      "Epoch 3/100\n",
      "2182/2182 [==============================] - 15s 7ms/step - loss: 0.9030 - mean_squared_error: 0.8581 - RMSE: 0.9029 - val_loss: 0.9271 - val_mean_squared_error: 0.9019 - val_RMSE: 0.9267\n",
      "Epoch 4/100\n",
      "2182/2182 [==============================] - 15s 7ms/step - loss: 0.8977 - mean_squared_error: 0.8492 - RMSE: 0.8977 - val_loss: 0.9251 - val_mean_squared_error: 0.8978 - val_RMSE: 0.9246\n",
      "Epoch 5/100\n",
      "2182/2182 [==============================] - 17s 8ms/step - loss: 0.8940 - mean_squared_error: 0.8398 - RMSE: 0.8940 - val_loss: 0.9234 - val_mean_squared_error: 0.8947 - val_RMSE: 0.9230\n",
      "Epoch 6/100\n",
      "2182/2182 [==============================] - 16s 7ms/step - loss: 0.8902 - mean_squared_error: 0.8329 - RMSE: 0.8902 - val_loss: 0.9221 - val_mean_squared_error: 0.8921 - val_RMSE: 0.9217\n",
      "Epoch 7/100\n",
      "2182/2182 [==============================] - 16s 7ms/step - loss: 0.8854 - mean_squared_error: 0.8253 - RMSE: 0.8854 - val_loss: 0.9211 - val_mean_squared_error: 0.8901 - val_RMSE: 0.9207\n",
      "Epoch 8/100\n",
      "2182/2182 [==============================] - 16s 7ms/step - loss: 0.8832 - mean_squared_error: 0.8196 - RMSE: 0.8832 - val_loss: 0.9203 - val_mean_squared_error: 0.8883 - val_RMSE: 0.9199\n",
      "Epoch 9/100\n",
      "2182/2182 [==============================] - 15s 7ms/step - loss: 0.8793 - mean_squared_error: 0.8123 - RMSE: 0.8793 - val_loss: 0.9200 - val_mean_squared_error: 0.8877 - val_RMSE: 0.9195\n",
      "Epoch 10/100\n",
      "2182/2182 [==============================] - 17s 8ms/step - loss: 0.8772 - mean_squared_error: 0.8089 - RMSE: 0.8772 - val_loss: 0.9199 - val_mean_squared_error: 0.8879 - val_RMSE: 0.9195\n",
      "Epoch 11/100\n",
      "2182/2182 [==============================] - 16s 7ms/step - loss: 0.8748 - mean_squared_error: 0.8055 - RMSE: 0.8748 - val_loss: 0.9197 - val_mean_squared_error: 0.8872 - val_RMSE: 0.9193\n",
      "Epoch 12/100\n",
      "2182/2182 [==============================] - 16s 7ms/step - loss: 0.8736 - mean_squared_error: 0.8007 - RMSE: 0.8736 - val_loss: 0.9194 - val_mean_squared_error: 0.8853 - val_RMSE: 0.9189\n",
      "Epoch 13/100\n",
      "2182/2182 [==============================] - 17s 8ms/step - loss: 0.8719 - mean_squared_error: 0.7976 - RMSE: 0.8719 - val_loss: 0.9199 - val_mean_squared_error: 0.8872 - val_RMSE: 0.9195\n",
      "Epoch 14/100\n",
      "2182/2182 [==============================] - 16s 7ms/step - loss: 0.8685 - mean_squared_error: 0.7931 - RMSE: 0.8685 - val_loss: 0.9200 - val_mean_squared_error: 0.8870 - val_RMSE: 0.9196\n",
      "Epoch 15/100\n",
      "2182/2182 [==============================] - 15s 7ms/step - loss: 0.8686 - mean_squared_error: 0.7921 - RMSE: 0.8686 - val_loss: 0.9205 - val_mean_squared_error: 0.8880 - val_RMSE: 0.9201\n",
      "Epoch 16/100\n",
      "2182/2182 [==============================] - 17s 8ms/step - loss: 0.8670 - mean_squared_error: 0.7888 - RMSE: 0.8670 - val_loss: 0.9210 - val_mean_squared_error: 0.8889 - val_RMSE: 0.9205\n",
      "Epoch 17/100\n",
      "2182/2182 [==============================] - 16s 7ms/step - loss: 0.8659 - mean_squared_error: 0.7883 - RMSE: 0.8659 - val_loss: 0.9213 - val_mean_squared_error: 0.8893 - val_RMSE: 0.9209\n",
      "Epoch 18/100\n",
      "2182/2182 [==============================] - 16s 8ms/step - loss: 0.8650 - mean_squared_error: 0.7858 - RMSE: 0.8650 - val_loss: 0.9219 - val_mean_squared_error: 0.8903 - val_RMSE: 0.9214\n",
      "Epoch 19/100\n",
      "2182/2182 [==============================] - 15s 7ms/step - loss: 0.8650 - mean_squared_error: 0.7849 - RMSE: 0.8650 - val_loss: 0.9223 - val_mean_squared_error: 0.8909 - val_RMSE: 0.9218\n",
      "Epoch 20/100\n",
      "2182/2182 [==============================] - 15s 7ms/step - loss: 0.8642 - mean_squared_error: 0.7841 - RMSE: 0.8642 - val_loss: 0.9232 - val_mean_squared_error: 0.8933 - val_RMSE: 0.9228\n",
      "Epoch 21/100\n",
      "2182/2182 [==============================] - 17s 8ms/step - loss: 0.8635 - mean_squared_error: 0.7822 - RMSE: 0.8635 - val_loss: 0.9236 - val_mean_squared_error: 0.8937 - val_RMSE: 0.9232\n",
      "Epoch 22/100\n",
      "2182/2182 [==============================] - 16s 7ms/step - loss: 0.8627 - mean_squared_error: 0.7810 - RMSE: 0.8626 - val_loss: 0.9237 - val_mean_squared_error: 0.8932 - val_RMSE: 0.9233\n"
     ]
    }
   ],
   "source": [
    "# Context variable을 사용한 추천엔진 결합 ##################################################################\n",
    "\n",
    "# Defining RMSE measure\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "recomm0 = Input(shape=(1,))                                           # User input\n",
    "recomm1 = Input(shape=(1,))                                           # Item input\n",
    "context = Input(shape=(19,))\n",
    "r0_layer = Dense(19)(recomm0)                                          # Recommender 1\n",
    "r0_layer = Activation('linear')(r0_layer)\n",
    "r0_layer = Flatten()(r0_layer)\n",
    "r1_layer = Dense(19)(recomm1)                                          # Recommender 2\n",
    "r1_layer = Activation('linear')(r1_layer)\n",
    "r1_layer = Flatten()(r1_layer)\n",
    "context_layer = Embedding(19,1)(context)\n",
    "context_layer = Dense(1)(context_layer)                               # Context variables\n",
    "context_layer = Activation('softmax')(context_layer)\n",
    "context_layer = Flatten()(context_layer)\n",
    "\n",
    "R = Concatenate()([r0_layer, r1_layer])\n",
    "interaction0_layer = Multiply()([r0_layer, context_layer])\n",
    "interaction1_layer = Multiply()([r1_layer, context_layer])\n",
    "\n",
    "# Neural network\n",
    "R = Dense(1024)(R)\n",
    "R = Activation('linear')(R)\n",
    "#R = Dropout(0.001)(R)\n",
    "\n",
    "R = Concatenate()([R, context_layer, interaction0_layer, interaction1_layer])\n",
    "\n",
    "# Adding more layers\n",
    "R = Dense(512)(R)\n",
    "R = Activation('tanh')(R)\n",
    "R = Dropout(0.02)(R)\n",
    "\n",
    "R = Dense(256)(R)\n",
    "R = Activation('tanh')(R)\n",
    "R = Dropout(0.02)(R)\n",
    "\n",
    "R = Dense(1)(R)\n",
    "\n",
    "model = Model(inputs=[recomm0, recomm1, context], outputs=R)\n",
    "model.compile(\n",
    "  loss=RMSE,\n",
    "  #optimizer=SGD(lr=0.001, momentum=0.95),\n",
    "  optimizer=Adamax(lr=0.0000002),\n",
    "  metrics=['mean_squared_error', RMSE]\n",
    ")\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'auto')\n",
    "\n",
    "result = model.fit(\n",
    "  x=[train0, train1, context_train],\n",
    "  y=ratings_train.rating.values.astype(np.float64),\n",
    "  epochs=100,\n",
    "  batch_size=32,\n",
    "  callbacks = [early_stopping],\n",
    "  validation_data=(\n",
    "    [test0, test1, context_test],\n",
    "    ratings_test.rating.values.astype(np.float64)\n",
    "  ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/936 [==============================] - 3s 3ms/step\n",
      "0.9450920364758103\n",
      "0.9739438535196879\n",
      "0.9552511026108002\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "predictions = np.ravel(model.predict([test0, test1, context_test]), order='C')\n",
    "predictions[predictions > 5] = 5\n",
    "predictions[predictions < 1] = 1\n",
    "print(RMSE2(np.array(ratings_test['rating']), predictions))   # 상황변수\n",
    "print(RMSE2(np.array(ratings_test['rating']), test0))         # fm\n",
    "print(RMSE2(np.array(ratings_test['rating']), test1))         # bs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rmse 3번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9452754706843991\n"
     ]
    }
   ],
   "source": [
    "context1 = 0.9450920364758103\n",
    "context2 = 0.948125174919919\n",
    "context3 = 0.9426092006574679\n",
    "\n",
    "print((context1+context2+context3) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('seongju': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ac64377bdf20d7c56505465f573d42c9a70025c609fb86d41fb4deb22be2428"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
